---
description: Acceptance Testing Mode overrides standard AAID instructions for acceptance-testing-blueprint
globs:
  - acceptance-test/**
alwaysApply: false
---

# AI Acceptance Testing Mode Rules

When this mode is active, ignore the default AAID/TDD rules for matching acceptance-testing files.

## Core Concepts

**Four-Layer Model:**

- Layer 1: Executable Specs (test cases) - WHAT in business language, only calls DSL
- Layer 2: DSL (Domain-Specific Language) - translates business language to driver calls, NO assertions
- Layer 3: Protocol Drivers + Stubs - HOW system is accessed, contains ALL assertions/failures
- Layer 4: SUT (System Under Test) - your actual deployed system (includes your DB, cache, services)

**Isolation (enables parallel & repeated test runs):**

Why isolation matters: Acceptance tests run against production-like SUT with real DB/cache (slower than unit tests). To keep test suites fast, we run tests in parallel. Isolation prevents tests from interfering with each other.

- **Functional isolation**: Each test creates unique domain partition (e.g., user account with aliased email)
- **Temporal isolation**: `params.alias("email")` takes `"user@test.com"` from args â†’ returns `"user@test.com1"`, `"user@test.com2"`, etc.
- Alias: account identifiers (emails, usernames), data names (todo names, order IDs)
- Don't alias: passwords, descriptions, roles (use `params.optional()` for defaults)

**Stubbing:**

- Stub ONLY external third-party APIs you don't control (payment gateways, email services)
- NEVER stub your own database, cache, or internal services - they're part of your SUT

**BDD â†’ Code transformation:**

```gherkin
Given the user has an account
And they have a completed todo "Buy milk"
```

becomes:

```typescript
await dsl.user.hasAccount({ email: "user@test.com" });
await dsl.user.hasCompletedTodo({ name: "Buy milk" });
```

## Primary Goal

Transform BDD scenarios (Given-When-Then format) into executable acceptance tests using the Four-Layer Model.

**Required Input:** BDD scenarios. If not provided, ask user for them before proceeding.

## Mode Recognition

**Acceptance Testing mode is ACTIVE when:**

- User explicitly requests acceptance testing, ATDD, transforming BDD scenarios, or work with the Four-Layer Model
- User provides BDD scenarios and asks for executable specifications, DSL layers, or protocol drivers
- Work happens inside `acceptance-test/**` touching Layer 1â€“3 artifacts

**NOT active:** Normal context sharing, unit-test/TDD work, or presentation-only changes

## Acceptance Testing Workflow Sequence

1. **Stage 1: Context** - Gather project/feature context, BDD scenarios, architecture
2. **Stage 2: Planning** - Extract domain concepts, choose driver type, outline isolation
3. **Stage 3: Three-Phase Cycle** - Phase 1 â†’ 2 â†’ 3 with review after each
4. **Stage 4: Complete** - Repeat or confirm done

## Three-Phase Test Cycle

Stop for review after every phase. Remember the current phase between messages.

### ðŸ”´ Phase 1 Â· Executable Spec & DSL (spec must fail)

- Map each BDD line to exactly one DSL call (see transformation example above)
- Use only `// Given`, `// When`, `// Then`, `// And`, `// But` comments in executable specs
- First action in each test: create account boundary (e.g., `dsl.user.hasAccount({ email: "..." })`)
- DSL methods: use `params.alias()` for identifiers, `params.optional()` for defaults
- Output: failing spec plus DSL layer skeleton â†’ stop for review

### ðŸŸ¢ Phase 2 Â· Protocol Driver Implementation

- Implement driver methods matching DSL names exactly, ensuring atomic success/failure and polling (no sleeps)
- Stub only external third-party systems (see stubbing rules above)
- All assertions/failures go in driver using `expect.fail()` or test framework's fail mechanism
- Output: specs passing through the driver (or report failures) â†’ stop for review

### ðŸ§¼ Phase 3 Â· Refine & Validate Isolation

- Verify system, functional, and temporal isolation
- Keep DSL natural language, remove duplication, ensure layer separation
- Output: polished four-layer solution with tests green â†’ stop for final review

## Critical Rules

- Always use `params.alias()` for identifiers (emails, usernames, todo names, order IDs) - enables parallel execution and repeatable runs
- Use `params.optional()` for non-essential parameters to keep DSL calls readable and business-focused
- Each test must create its own domain partition (e.g., unique account) as first step
- DSL names mirror BDD wording exactly (`hasCompletedTodo`, `archives`, `confirmInArchive`)
- Driver methods do not return booleans; they fail directly via test framework or succeed silently
- Multi-step flows hidden in driver (e.g., `hasAccount` does register + login internally)
- Polling with timeouts for async operations; no arbitrary `sleep()` calls

## Domain Concept Extraction

From BDD scenarios (and Ubiquitous Language glossary if provided), extract domain concepts to partition DSL:

- **Domain entities** â†’ DSL objects: Identify key actors/aggregates (User, Todo, Order) â†’ create `dsl.user`, `dsl.todo`, `dsl.order`
- **Actions on entities** â†’ DSL methods: Verbs from scenarios â†’ `hasCompletedTodo()`, `archives()`, `placeOrder()`
- **Expected outcomes** â†’ Verification methods: Use "confirm" prefix â†’ `confirmInArchive()`, `confirmErrorMessage()`

Partition by domain concern, not by technical layer. Each DSL object represents a distinct domain concept.
