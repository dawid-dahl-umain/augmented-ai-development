## Onboarding Level 7: See It in Action - The Demo Repository

| Level 0 | Level 1 |   Level 2    |    Level 3     | Level 4 |    Level 5     |  Level 6  |    Level 7    | Start |
| :-----: | :-----: | :----------: | :------------: | :-----: | :------------: | :-------: | :-----------: | ----- |
|   ‚úÖ    |   ‚úÖ    |      ‚úÖ      |       ‚úÖ       |   ‚úÖ    |       ‚úÖ       |    ‚úÖ     |  üìç **YOU**   | ‚è∏Ô∏è    |
| Problem | Mindset | How It Works | The Three Ways | Visual  | TDD Catches AI | Your Work | **Demo Repo** | Ready |

**‚è±Ô∏è Time: 10 minutes**

**In this level:**

- [What's Special About This Demo?](#whats-special-about-this-demo)
- [Unit Tests: Pure Domain Logic](#unit-tests-pure-domain-logic)
- [Integration Tests: Technical Adapters](#integration-tests-technical-adapters)
- [Acceptance Tests: The Complete System](#acceptance-tests-the-complete-system)
- [Solving the E2E Testing Nightmare](#solving-the-e2e-testing-nightmare)
- [The Critical Difference](#the-critical-difference)
- [Architecture That Emerged From Tests](#architecture-that-emerged-from-tests)
- [Try It Yourself](#try-it-yourself)

![See It in Action - The Demo Repository](../../../assets/onboarding/7.webp)

Ready to see `AAID` in action? Let's explore a real TicTacToe game built following `AAID` discipline.

**100%** of the code, every single line, was generated by an AI agent, in close collaboration with the developer.

**[‚Üí View the Demo Repository](https://github.com/dawid-dahl-umain/augmented-ai-development-demo)**

| ‚òùÔ∏è                                                                                                                                                                                                                                                                                                                                                                                             |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| "**This is so incredibly over-engineered for a simple TicTacToe game!**"<br /><br />If you looked at the demo repo and thought that, you'd be correct! The demo's purpose, however, isn't to show how to build TicTacToe, but to present how parts of a real more complex system might look, when using the `AAID` workflow. In a demo codebase simple enough to explore in around 10 minutes. |

<a id="whats-special-about-this-demo"></a>

### What's Special About This Demo?

This isn't just a TicTacToe game. It showcases what results from using `AAID` with **three different types of testing**, corresponding to the three ways you learned in Level 3:

```
Unit Tests        ‚Üí Way 1: Business Behavior (the main `AAID` TDD flow)
Integration Tests ‚Üí Way 2: Technical Infrastructure (TDD for technical contracts)
Acceptance Tests  ‚Üí Full system validation (a different `AAID` workflow for acceptance testing)
```

Let's see what each type does and why they matter.

<a id="unit-tests-pure-domain-logic"></a>

### üî¨ Unit Tests: Pure Domain Logic

**Location**: [`src/domain/tic-tac-toe/game.spec.ts`](https://github.com/dawid-dahl-umain/augmented-ai-development-demo/blob/main/src/domain/tic-tac-toe/game.spec.ts)

These follow the **main `AAID` TDD workflow** you've been learning about:

```typescript
describe("Player makes a move", () => {
  it("places mark on empty cell and switches turn", () => {
    // Given
    const initialState = TicTacToe.start()

    // When
    const nextState = TicTacToe.play(initialState, 5)

    // Then
    expect(nextState.board[5]).toBe("X")
    expect(nextState.currentPlayer).toBe("O")
  })
})
```

**Key point**: This is the RED‚ÜíGREEN‚ÜíREFACTOR cycle from the main guide. The AI wrote these tests first, then implemented just enough code to pass. No database, no UI, just pure game rules (Way 1: Business Behavior from Level 3).

<a id="integration-tests-technical-adapters"></a>

### üîå Integration Tests: Technical Adapters

**Location**: [`src/adapters/cli/input/cli-input-adapter/cli-input-adapter.spec.ts`](https://github.com/dawid-dahl-umain/augmented-ai-development-demo/blob/main/src/adapters/cli/input/cli-input-adapter/cli-input-adapter.spec.ts)

These also use TDD, but for testing how adapters connect domain logic to the outside world:

```typescript
it("starts a new game on 'start' and presents initial state", () => {
  // Given
  const presenter = { presentState: vi.fn(), ... }
  const adapter = new CliInputAdapter(presenter)

  // When
  adapter.handle("start")

  // Then
  expect(presenter.presentState).toHaveBeenCalledWith(
    expect.objectContaining({ currentPlayer: "X" })
  )
})
```

**Key point**: Still TDD, but testing technical contracts (how adapters translate between layers) rather than business logic. This is Way 2: Technical Infrastructure from Level 3.

The demo's integration tests mock the output dependencies for speed and isolation. In systems with databases or other managed dependencies (databases, Redis, queues), integration tests would however use the real app resources to verify the adapter's integration. While demo uses mocks for the console I/O, the real compiled CLI binary (with real I/O) is tested at the acceptance test level.

<a id="acceptance-tests-the-complete-system"></a>

### üéØ Acceptance Tests: The Complete System

**Location**: [`acceptance-test/executable-specs/`](https://github.com/dawid-dahl-umain/augmented-ai-development-demo/tree/main/acceptance-test/executable-specs)

Here's where things get different. Acceptance tests use a **different `AAID` workflow**, based on Dave Farley's Four-Layer Model.

Let's have a look at this specification:

```gherkin
Scenario: Valid move on empty cell
  Given it is player X's turn
  And position 5 is empty
  When player X places their mark at position 5
  Then position 5 should contain X
  And it should be player O's turn
```

See how the test literally _becomes_ executable? Mapping 1:1 in readable language:

```typescript
it("should accept a valid move on an empty cell", async () => {
  // Given
  dsl.game.start()
  dsl.player.isTurn("X")
  dsl.board.isPositionEmpty(5)

  // When
  dsl.player.placeMark("X", 5)

  // Then
  dsl.board.confirmPositionContains(5, "X")
  dsl.player.confirmNextTurn("O")
})
```

**Key point**: This test reads like the [BDD specification](https://github.com/dawid-dahl-umain/augmented-ai-development-demo/blob/main/specification-package/tictactoe-bdd-specification-package.md) because it **IS the specification**. Through a DSL (Domain-Specific Language), the specs become executable tests that run the compiled CLI, aka: the **actual** system to be deployed.

| ‚òùÔ∏è                                                                                                                                                                                                                      |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| You don't need to learn the `AAID` acceptance test workflow right now! Focus on the main workflow you've been learning about.<br /><br />But it is good to know it exists, for when you need full system (E2E) testing. |

<a id="solving-the-e2e-testing-nightmare"></a>

### Solving the E2E Testing Nightmare

Ever experienced these E2E testing problems?

- **Test passes Monday, fails Tuesday** (no code changes)
- **Can't run tests in parallel** (they interfere with each other)
- **"Works on my machine"** syndrome
- **Cleanup scripts that don't actually clean up**

The demo also presents the isolation patterns designed to eliminate these issues:

**System Isolation** - Tests become stable and focus _only_ on what your team is responsible for:

```typescript
// Your system: database, cache, queues ‚Üí Use REAL
// External APIs: Stripe, SendGrid, Pok√©mon API ‚Üí Stub/mock (and consider Contract Testing)
// Result: Tests verify your actual system behavior
```

**Functional Isolation** - Tests run in parallel without interference:

```typescript
// Test A: Creates user "alice@test.com1" with their todos
// Test B: Creates user "alice@test.com2" with their todos
// Same database, different data boundaries
```

**Temporal Isolation** - Tests never collide with previous runs:

```typescript
// Your test says: "Buy milk"
// First run creates: "Buy milk1"
// Second run creates: "Buy milk2"
// No cleanup needed!
```

The [`acceptance-test/dsl/utils/`](https://github.com/dawid-dahl-umain/augmented-ai-development-demo/tree/main/acceptance-test/dsl/utils) utilities created by Dave Farley helps with this test isolation. Your tests stay readable while being bulletproof.

<a id="the-critical-difference"></a>

### The Critical Difference

**Unit/Integration tests** (main `AAID` flow):

- **Used to build the system technically**
- Guided by BDD specs but don't map 1:1
- Developer adds extra tests as needed (especially for technical edge cases)
- Test individual parts in isolation
- Domain logic stays close to BDD scenarios; technical tests add more as needed

**Acceptance tests** (different `AAID` workflow):

- **Used to confirm that the system is releasable (fulfills specs)**
- MUST map exactly 1:1 (or as closely as possible) to BDD scenarios via DSL
- Tests ARE the specifications (executable definition of done)
- Test the complete production-like system (not individual parts)
- Run the real system through its actual entry points

This fundamental difference is why acceptance tests need their own [specialized workflow](https://github.com/dawid-dahl-umain/augmented-ai-development/blob/main/appendices/appendix-a/docs/aaid-acceptance-testing-workflow.md). The main guide prepares you for unit and integration testing, **master that first**. Then explore acceptance testing when you're ready.

<a id="architecture-that-emerged-from-tests"></a>

### Architecture That Emerged From Tests

The repository showcases clean hexagonal architecture that emerged from the `AAID` process, in close collaboration with the developer:

```
src/
‚îú‚îÄ‚îÄ domain/tic-tac-toe/        ‚Üí Pure game logic (no I/O, immutable)
‚îî‚îÄ‚îÄ adapters/cli/              ‚Üí I/O boundaries
    ‚îú‚îÄ‚îÄ input/                 ‚Üí CLI commands ‚Üí domain calls
    ‚îî‚îÄ‚îÄ output/                ‚Üí Domain state ‚Üí display text

acceptance-test/
‚îú‚îÄ‚îÄ executable-specs/          ‚Üí 15 BDD tests (1:1 with specifications)
‚îú‚îÄ‚îÄ dsl/                       ‚Üí Business vocabulary layer
‚îú‚îÄ‚îÄ protocol-driver/           ‚Üí Executes real CLI
‚îî‚îÄ‚îÄ sut/                       ‚Üí System under test notes
```

<a id="try-it-yourself"></a>

### Try It Yourself

Feel free to explore the code in the repo, and try it yourself!

```bash
# Clone and explore
git clone https://github.com/dawid-dahl-umain/augmented-ai-development-demo.git
cd augmented-ai-development-demo

# Install dependencies
pnpm install

# Run all tests - watch them all pass (100% coverage!)
pnpm test

# See test isolation in action (9 demo tests)
pnpm exec vitest run acceptance-test-isolation-demo

# Play the actual game
pnpm start --moves 1,4,2,5,3
```

---

**üõë Checkpoint**: Ready to start?

- **"I want to try this"** ‚Üí Continue to [Get Started](./get-started.md) to begin your `AAID` journey
- **"Show me the demo repo first"** ‚Üí Clone it and explore! The link is at the top of this level
- **"I need more context"** ‚Üí Review [Level 4](./4.md) for the workflow diagram

---

‚úÖ **Progress: 87%** | Next: Get Started - Your Turn to Try `AAID`

---

‚¨ÖÔ∏è Back to [AAID Onboarding Guide](../guide.md)
