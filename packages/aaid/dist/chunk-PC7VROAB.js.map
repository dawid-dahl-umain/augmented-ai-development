{"version":3,"sources":["../src/prompts/index.ts","../src/prompts/investigation-and-problem-solving/index.ts","../../../reusable-prompts/investigation-and-problem-solving/analyze-&-stop.md","../../../reusable-prompts/investigation-and-problem-solving/analyze-command-&-stop.md","../../../reusable-prompts/investigation-and-problem-solving/debug-&-stop.md","../../../reusable-prompts/investigation-and-problem-solving/minimal-fix-&-analyze-&-stop.md","../../../reusable-prompts/investigation-and-problem-solving/research-&-stop.md","../src/prompts/misc/index.ts","../../../reusable-prompts/misc/gherkin-guard.md","../../../reusable-prompts/misc/git-commit.md","../src/prompts/setup-and-planning/index.ts","../../../reusable-prompts/setup-and-planning/ai-presentation-roadmap-template.md","../../../reusable-prompts/setup-and-planning/ai-roadmap-template.md","../../../reusable-prompts/setup-and-planning/ai-technical-roadmap-template.md","../../../reusable-prompts/setup-and-planning/project-context.md","../src/prompts/tdd/index.ts","../../../reusable-prompts/tdd/green-&-stop.md","../../../reusable-prompts/tdd/red-&-stop.md","../../../reusable-prompts/tdd/refactor-&-stop.md"],"names":[],"mappings":";;;AAAA,IAAA,eAAA,GAAA;AAAA,QAAA,CAAA,eAAA,EAAA;AAAA,EAAA,8BAAA,EAAA,MAAA,yCAAA;AAAA,EAAA,IAAA,EAAA,MAAA,YAAA;AAAA,EAAA,gBAAA,EAAA,MAAA,0BAAA;AAAA,EAAA,GAAA,EAAA,MAAA;AAAA,CAAA,CAAA;;;ACAA,IAAA,yCAAA,GAAA;AAAA,QAAA,CAAA,yCAAA,EAAA;AAAA,EAAA,cAAA,EAAA,MAAA,cAAA;AAAA,EAAA,qBAAA,EAAA,MAAA,qBAAA;AAAA,EAAA,YAAA,EAAA,MAAA,YAAA;AAAA,EAAA,2BAAA,EAAA,MAAA,2BAAA;AAAA,EAAA,eAAA,EAAA,MAAA;AAAA,CAAA,CAAA;;;ACAA,IAAA,oBAAA,GAAA,kaAAA;;;ACAA,IAAA,4BAAA,GAAA,yPAAA;;;ACAA,IAAA,kBAAA,GAAA,+XAAA;;;ACAA,IAAA,gCAAA,GAAA,oeAAA;;;ACAA,IAAA,qBAAA,GAAA,qoDAAA;;;ALMO,IAAM,cAAA,GAAyB,oBAAA;AAC/B,IAAM,qBAAA,GAAgC,4BAAA;AACtC,IAAM,YAAA,GAAuB,kBAAA;AAC7B,IAAM,2BAAA,GACX,gCAAA;AACK,IAAM,eAAA,GAA0B,qBAAA;;;AMXvC,IAAA,YAAA,GAAA;AAAA,QAAA,CAAA,YAAA,EAAA;AAAA,EAAA,YAAA,EAAA,MAAA,YAAA;AAAA,EAAA,SAAA,EAAA,MAAA;AAAA,CAAA,CAAA;;;ACAA,IAAA,qBAAA,GAAA,0yGAAA;;;ACAA,IAAA,kBAAA,GAAA,wOAAA;;;AFGO,IAAM,YAAA,GAAuB,qBAAA;AAC7B,IAAM,SAAA,GAAoB,kBAAA;;;AGJjC,IAAA,0BAAA,GAAA;AAAA,QAAA,CAAA,0BAAA,EAAA;AAAA,EAAA,6BAAA,EAAA,MAAA,6BAAA;AAAA,EAAA,iBAAA,EAAA,MAAA,iBAAA;AAAA,EAAA,0BAAA,EAAA,MAAA,0BAAA;AAAA,EAAA,cAAA,EAAA,MAAA;AAAA,CAAA,CAAA;;;ACAA,IAAA,wCAAA,GAAA,uoRAAA;;;ACAA,IAAA,2BAAA,GAAA,umNAAA;;;ACAA,IAAA,qCAAA,GAAA,+4SAAA;;;ACAA,IAAA,uBAAA,GAAA,gHAAA;;;AJKO,IAAM,6BAAA,GACX,wCAAA;AACK,IAAM,iBAAA,GAA4B,2BAAA;AAClC,IAAM,0BAAA,GAAqC,qCAAA;AAC3C,IAAM,cAAA,GAAyB,uBAAA;;;AKTtC,IAAA,WAAA,GAAA;AAAA,QAAA,CAAA,WAAA,EAAA;AAAA,EAAA,YAAA,EAAA,MAAA,YAAA;AAAA,EAAA,UAAA,EAAA,MAAA,UAAA;AAAA,EAAA,eAAA,EAAA,MAAA;AAAA,CAAA,CAAA;;;ACAA,IAAA,kBAAA,GAAA,kRAAA;;;ACAA,IAAA,gBAAA,GAAA,8QAAA;;;ACAA,IAAA,qBAAA,GAAA,wRAAA;;;AHIO,IAAM,YAAA,GAAuB,kBAAA;AAC7B,IAAM,UAAA,GAAqB,gBAAA;AAC3B,IAAM,eAAA,GAA0B,qBAAA","file":"chunk-PC7VROAB.js","sourcesContent":["export * as investigationAndProblemSolving from \"./investigation-and-problem-solving\";\nexport * as misc from \"./misc\";\nexport * as setupAndPlanning from \"./setup-and-planning\";\nexport * as tdd from \"./tdd\";\n","import analyzeAndStopSrc from \"./analyze-&-stop.md\";\nimport analyzeCommandAndStopSrc from \"./analyze-command-&-stop.md\";\nimport debugAndStopSrc from \"./debug-&-stop.md\";\nimport minimalFixAndAnalyzeAndStopSrc from \"./minimal-fix-&-analyze-&-stop.md\";\nimport researchAndStopSrc from \"./research-&-stop.md\";\n\nexport const analyzeAndStop: string = analyzeAndStopSrc;\nexport const analyzeCommandAndStop: string = analyzeCommandAndStopSrc;\nexport const debugAndStop: string = debugAndStopSrc;\nexport const minimalFixAndAnalyzeAndStop: string =\n  minimalFixAndAnalyzeAndStopSrc;\nexport const researchAndStop: string = researchAndStopSrc;\n","Analyze the issue, scan relevant files, optionally consult docs, summarize next steps. Stop.\n\nI repeat: DO NOT CHANGE ANY CODE AFTER THE COMMAND:\n\n1. Analyze issue or task at hand\n2. Research any relevant files for context\n   a. Optional: use the web tool for documentation\n3. Analyze how to solve it or how to move forward\n4. Report back with your findings\n5. STOP. DON'T CHANGE, ADD, OR DELETE ANYTHING.\n","Run the command, but if it fails, analyze, report back then STOP.\n\nI repeat: DO NOT CHANGE ANY CODE AFTER THE COMMAND:\n\n1. Run command\n2. Analyze the result\n3. Report back with your findings\n4. STOP. DON'T CHANGE, ADD, OR DELETE ANYTHING.\n","Debug and research any relevant files for context, report back then STOP.\n\nI repeat: DO NOT CHANGE ANY CODE AFTER THE COMMAND:\n\n1. Add debug logs\n2. Research any relevant files for context\n   a. Optional: use the web tool for documentation\n3. Run the command necessary to analyze the logs\n4. Report back with your findings\n5. STOP. DON'T CHANGE, ADD, OR DELETE ANYTHING.\n","Implement the simplest and cleanest fix, analyze and research any relevant files for context, then verify if the fix was successful or not, report back then STOP.\n\nI repeat: DO NOT CHANGE ANY CODE AFTER THE COMMAND:\n\n1. Research any relevant files for context\n2. Implement the cleanest and simplest fix\n3. Verify success or failure of the fix by running tests and/or code\n4. Analyze result\n5. Report back with your findings\n6. STOP. DON'T CHANGE, ADD, OR DELETE ANYTHING.\n","# Research & Stop\n\nResearch the codebase and relevant documentation to gather context for the current task. Stop when complete.\n\n**IMPORTANT: READ-ONLY RESEARCH ONLY. DO NOT MODIFY, CREATE, OR DELETE ANY FILES OR CODE WHEN RESEARCHING.**\n\n## Instructions\n\n1. **Search Codebase**\n\n   - Find existing patterns, components, or implementations related to the task\n   - Locate relevant utility functions, types, interfaces, or shared code\n   - Find similar features or test examples that can guide the work\n   - Identify architectural patterns and conventions being used\n\n2. **Search Documentation** (when relevant)\n\n   - Look up official documentation for frameworks/libraries being used\n   - Find best practices for the current approach\n   - Research API documentation or technical specifications\n   - Use web search tool if needed\n\n3. **Report Findings**\n\n   - Summarize relevant patterns and code found\n   - Highlight existing implementations to reference or extend\n   - Note important constraints, conventions, or decisions\n   - Provide links to helpful documentation\n   - Recommend next steps\n\n4. **STOP**\n   - Wait for user review and direction\n\n## Usage Throughout AAID: Augmented AI Development\n\n- **Stage 1 (Context)**: Gather broad project patterns and architecture\n- **Stage 2 (Planning)**: Research specific approaches for the planned feature\n- **Stage 4 (TDD)**: Research implementation approaches, testing patterns, or debug issues\n- **General Development**: Investigate APIs, libraries, or solve specific problems\n\nNote: If AAID development rules don't seem to be available, request them for full workflow context.\n","import gherkinGuardSrc from \"./gherkin-guard.md\";\nimport gitCommitSrc from \"./git-commit.md\";\n\nexport const gherkinGuard: string = gherkinGuardSrc;\nexport const gitCommit: string = gitCommitSrc;\n","# Gherkin Guard Command\n\nEnforce consistent Gherkin-style Given/When/Then comments in all tests to maintain readability and structure. Use this command to review existing tests or generate new ones following team standards.\n\n## Goal\n\nEnforce our Gherkin-style Given/When/Then comments in tests without changing behavior.\n\n## Supported Structures\n\nChoose one per test:\n\n- **A) Standard:** `// Given` → `// When` → `// Then`\n- **B) Minimal:** `// When` → `// Then` (only when no setup is needed)\n\n## Notes (Spec vs. Team Style)\n\n- Gherkin allows multiple Then steps; our team style restricts to one `// Then`. Use `// And` or `// But` for additional expectations.\n\n## Team Rules — Structure\n\n- Exactly one `// Then`. Extra expectations go under the same `// Then` as `// And` (or `// But`). No second `// Then`.\n- If additional expectations aren't tightly related to the same behavior, prefer a **separate test case**.\n- `// When` is one triggering event. If more seem needed, move prep to `// Given` or split; use `// And` after `// When` only if inseparable.\n- No assertions in `// Given` or `// When`.\n- No loops/conditionals inside tests.\n- Do **not** include an empty `// Given`. If there's no setup, use structure B.\n\n## Team Rules — Formatting\n\n- Comments must be exactly: `// Given`, `// When`, `// Then`, `// And`, `// But` (capitalized; one space after `//`; no extra text).\n- The code for a section starts on the next line (no blank line between the comment and its code).\n- No empty section comments.\n- Exactly 1 blank line between sections.\n\n## Action\n\n- **New tests:** Generate following these rules\n- **Existing tests:** Rewrite to comply, preserving intent and outcome\n- **Output:** Final test code only (no explanations unless requested)\n- **For major changes:** Alert user before rewriting if structure changes significantly\n\n## Self-Check (Internal Use)\n\nVerify all are true before outputting:\n\n- [ ] Uses A (`Given`/`When`/`Then`) or B (`When`/`Then`)\n- [ ] `When` is one triggering event (`And` only if inseparable)\n- [ ] Extra expectations use `And`/`But` (no extra `Then`)\n- [ ] If expectations aren't tightly related, split into another test\n- [ ] No assertions in `Given`/`When`; no loops/conditionals\n- [ ] Comment casing/spacing exact; no extra text\n- [ ] No empty sections; no blank line between comment and its code\n- [ ] Exactly 1 blank line between sections\n\n## Examples (Valid Per Our Team Style)\n\n### 1: Standard\n\n```ts\nit(\"adds a new item to the list\", () => {\n  // Given\n  const list = createList();\n\n  // When\n  list.add(\"Milk\");\n\n  // Then\n  expect(list.items).toContain(\"Milk\");\n});\n```\n\n### 2: Minimal (No Setup)\n\n```ts\nit(\"returns empty results for an unknown query\", () => {\n  // When\n  const results = search(\"unknown\");\n\n  // Then\n  expect(results).toHaveLength(0);\n});\n```\n\n### 3: Multiple Expectations via And/But\n\n```ts\nit(\"authenticates a user but locks on too many attempts\", () => {\n  // Given\n  const auth = createAuth();\n  auth.failLogin(\"alice\");\n  auth.failLogin(\"alice\");\n\n  // When\n  auth.failLogin(\"alice\");\n\n  // Then\n  expect(auth.isAuthenticated()).toBe(false);\n\n  // And\n  expect(auth.attempts(\"alice\")).toBe(3);\n\n  // But\n  expect(auth.isLocked(\"alice\")).toBe(true);\n});\n```\n","1. Do \"git add .\" to add all changes\n2. Follow our git commit message guidelines (See Cursor User Rules) and construct a good and clean commit message\n3. Commit with that message\n4. Do not push. The user will do that manually\n","import aiPresentationRoadmapTemplateSrc from \"./ai-presentation-roadmap-template.md\";\nimport aiRoadmapTemplateSrc from \"./ai-roadmap-template.md\";\nimport aiTechnicalRoadmapTemplateSrc from \"./ai-technical-roadmap-template.md\";\nimport projectContextSrc from \"./project-context.md\";\n\nexport const aiPresentationRoadmapTemplate: string =\n  aiPresentationRoadmapTemplateSrc;\nexport const aiRoadmapTemplate: string = aiRoadmapTemplateSrc;\nexport const aiTechnicalRoadmapTemplate: string = aiTechnicalRoadmapTemplateSrc;\nexport const projectContext: string = projectContextSrc;\n","# AI Presentation/UI Roadmap Template\n\nCreate a high-level roadmap for presentation/UI elements (pure visual, audio, or sensory aspects) that complements the behavioral implementation. This roadmap guides validation without using TDD, as these elements are validated through manual review and automated visual/accessibility tools.\n\nWhen done, ask user if the roadmap file should be saved to /ai-roadmaps/presentation directory. Create directory if not exists.\n\n**First, if anything is unclear about the design requirements or constraints, ask for clarification rather than making assumptions.**\n\n## Core Validation Principle for Presentation Elements\n\nWhen generating validation sequences, remember:\n\n- Validate sensory presentation, not system behavior\n- The domain and adapters already handle functionality: trust them\n- Focus on what users EXPERIENCE: visuals, sounds, haptic feedback, screen reader announcements\n- Manual review is the primary validation method\n\n## Format\n\n```markdown\n# Presentation/UI Roadmap: [UI Element/Feature Name]\n\n## Overview\n\n[2-3 sentences describing the sensory purpose and user experience goals]\n\n## Element Type\n\n[Component Styling | Layout | Animation | Typography | Theme | Icons | Audio | Haptic | Accessibility Announcements | Other]\n\n## System View\n\n[Create a diagram ONLY if the presentation has complex component hierarchies,\nmulti-step animations, or state-dependent styling that benefits from visualization.\nOtherwise, write \"No diagram needed - [brief reason]\"]\n\n<!-- If diagram is beneficial, choose appropriate type:\n- Component hierarchy diagram\n- Animation timeline/sequence\n- Responsive layout structure\n- Or describe the visual structure in text -->\n<!-- For simple styling like \"button color changes on hover\", text is sufficient -->\n\n## Design Integration\n\n- **Design Source**: [Figma link, style guide reference, audio specifications]\n- **Affected Components**: [What UI elements this touches]\n- **Design Tokens**: [Colors, spacing, typography scales, timing values used]\n\n## Spec References\n\n- [UI task ticket reference (e.g., UI-103)]\n- [Design system documentation]\n- [Figma or other design tool links]\n- [Brand guidelines if applicable]\n\n## Validation Sequence\n\n<!-- Describe what should be verified through human senses -->\n<!-- These are checklist items for manual review, NOT primarily automated tests -->\n<!-- Focus on sensory experience: visual, audio, haptic, screen reader announcements -->\n\n1. [Visual match to design specifications]\n2. [Responsive behavior across breakpoints]\n3. [Accessibility compliance (contrast, screen reader, keyboard navigation)]\n4. [Theme variants (dark/light mode) if applicable]\n5. [Animation performance and smoothness]\n6. [Cross-browser visual consistency]\n7. [Sensory feedback appropriateness]\n<!-- Continue as needed for this presentation element -->\n\n## Validation Strategy\n\n**Primary method**: Manual design review\n\n**Supporting methods** (where applicable):\n\n- Visual regression testing (e.g., Chromatic, Percy)\n- Accessibility audits (e.g., axe, WAVE)\n- Cross-browser testing (BrowserStack, manual)\n- Performance profiling for animations\n- User testing for subjective \"feel\"\n\n## Design Constraints\n\n<!-- Include relevant NFR categories for presentation -->\n\n- **Accessibility**: [WCAG level, contrast requirements, or \"WCAG 2.1 AA compliance\"]\n- **Performance**: [Animation FPS, paint times, or \"60fps animations\"]\n- **Browser Support**: [Specific versions or \"Last 2 major versions\"]\n- **Responsive Design**: [Breakpoints, approach, or \"Mobile-first, 320-1920px\"]\n\n## Dependencies\n\n- **Depends on**: [Design tokens, component library, base styles]\n- **Blocks/Enables**: [What can't proceed until this is done / What this unlocks]\n\n## Notes\n\n[Design decisions, trade-offs, or questions for designers]\n```\n\n## Examples\n\nHere are examples of how the generated roadmaps should look, when properly following the roadmap template format above.\n\n### Example 1: Archive Button Visual States\n\n```markdown\n# Presentation/UI Roadmap: Archive Button Visual States\n\n## Overview\n\nVisual styling for archive button to provide clear affordance and feedback. Ensures consistent visual language and accessibility across all button states.\n\n## Element Type\n\nComponent Styling\n\n## System View\n\nNo diagram needed - straightforward styling of existing button component with state variations\n\n## Design Integration\n\n- **Design Source**: Figma - Todo Actions v3.2, frame \"Archive States\"\n- **Affected Components**: TodoItem, ActionBar, BulkActions\n- **Design Tokens**: --color-action-secondary, --spacing-md, --transition-standard\n\n## Spec References\n\n- UI-103: Archive button visual states task\n- Design system v2.1 - Button component\n- Figma: https://figma.com/file/xxx/todo-actions?node-id=123\n\n## Validation Sequence\n\n1. Idle state matches Figma design (color, padding, border)\n2. Hover state shows correct elevation and color shift\n3. Active/pressed state provides appropriate feedback\n4. Disabled state clearly indicates unavailability\n5. Focus indicator remains visible and meets 3:1 contrast ratio\n6. Loading spinner animates smoothly\n7. Dark mode applies correct color tokens\n8. Touch target meets 44x44px minimum\n9. Screen reader announces state changes appropriately\n\n## Validation Strategy\n\n**Primary method**: Manual design review with designer\n\n**Supporting methods**:\n\n- Chromatic visual regression for all states\n- axe-core accessibility scan for contrast/ARIA\n- BrowserStack for cross-browser testing\n- Lighthouse for performance metrics\n\n## Design Constraints\n\n- **Accessibility**: WCAG 2.1 AA, visible focus states, proper ARIA labels\n- **Performance**: Transitions under 16ms paint time, no layout shift\n- **Browser Support**: Chrome, Firefox, Safari, Edge (last 2 versions)\n- **Responsive Design**: Maintains proportions 320px to 1920px\n\n## Dependencies\n\n- **Depends on**: Base button component, design token system\n- **Blocks/Enables**: Archive feature user testing, Marketing demo\n\n## Notes\n\n- Consider reduced motion preferences for animations\n- Loading state needs UX writing for screen readers\n- Discussed 3D transform with design team - postponed to v2\n```\n\n### Example 2: Success Notification Toast\n\n```markdown\n# Presentation/UI Roadmap: Success Notification Toast\n\n## Overview\n\nToast notification that appears after successful actions. Provides non-intrusive feedback with smooth animations and proper accessibility announcements.\n\n## Element Type\n\nAnimation\n\n## System View\n\n\\`\\`\\`mermaid\nstateDiagram-v2\n[*] --> Hidden\nHidden --> SlideIn: Trigger\nSlideIn --> Visible: 300ms\nVisible --> FadeOut: 4s timer\nVisible --> FadeOut: User dismiss\nFadeOut --> Hidden: 200ms\nHidden --> [*]\n\\`\\`\\`\n\n## Design Integration\n\n- **Design Source**: Figma - Notification System v1.5\n- **Affected Components**: ToastContainer, NotificationStack\n- **Design Tokens**: --animation-slide-in, --duration-toast, --elevation-raised\n\n## Spec References\n\n- UI-108: Toast notification implementation\n- Motion design guidelines section 2.4\n- Material Design toast reference\n\n## Validation Sequence\n\n1. Slide-in animation matches design timing (300ms ease-out)\n2. Position respects safe areas on mobile devices\n3. Multiple toasts stack correctly\n4. Auto-dismisses after 4 seconds with fade-out\n5. Progress bar indicates time remaining\n6. Dismiss button remains easily clickable/tappable\n7. Screen reader announces immediately with role=\"alert\"\n8. Respects prefers-reduced-motion settings\n9. Z-index keeps toast above all content\n10. Text remains readable over any background\n\n## Validation Strategy\n\n**Primary method**: Manual review with motion designer\n\n**Supporting methods**:\n\n- Record animations for frame-by-frame review\n- Test with actual screen readers (NVDA, JAWS, VoiceOver)\n- Performance profiling for 60fps validation\n- A/B test timing with users\n\n## Design Constraints\n\n- **Accessibility**: Immediate announcement, dismissible, keyboard navigable\n- **Performance**: 60fps animation, no jank, GPU-accelerated\n- **Browser Support**: All modern browsers including mobile\n- **Responsive Design**: Adapts position for mobile/tablet/desktop\n\n## Dependencies\n\n- **Depends on**: Animation library, Portal/Layer system\n- **Blocks/Enables**: Error notification variants, Undo functionality\n\n## Notes\n\n- Test with real users who rely on screen readers\n- Consider haptic feedback on mobile for important notifications\n- May need to adjust timing based on message length\n```\n\n---\n\n⬅️ Back to: [Appendix D](../../appendices/appendix-d-handling-technical-implementation-details.md)\n","# AI Domain/Business Logic Roadmap Template\n\nCreate a high-level roadmap for domain/business logic features that guides TDD without prescribing implementation details. This roadmap focuses on behavioral requirements and test scenarios that will emerge through the TDD process.\n\nWhen done, ask user if the roadmap file should be saved to /ai-roadmaps directory. Create directory if not exists.\n\n**First, if anything is unclear about the business requirements or acceptance criteria, ask for clarification rather than making assumptions.**\n\n## Core Testing Principle for Domain Logic\n\nWhen generating test sequences, remember:\n\n- Test business behavior, not technical implementation\n- Focus on WHAT the system should do, not HOW\n- Each test should force one small piece of functionality\n- Start with simplest test and build incrementally\n- Implementation details emerge through the RED-GREEN-REFACTOR cycle\n\n## Format\n\n```markdown\n# Domain/Business Logic Roadmap: [Feature Name]\n\n## Overview\n\n[2-3 sentences describing the business value and user-facing behavior this feature provides]\n\n## System View\n\n[Create a diagram ONLY if the feature involves multiple components/services interacting,\ncomplex flows, or state transitions that benefit from visualization.\nOtherwise, write \"No diagram needed - [brief reason]\"]\n\n<!-- If diagram is beneficial, choose appropriate type:\n- Mermaid diagram for component interactions\n- State diagram for workflows\n- Sequence diagram for complex flows\n- Or describe the system view in text -->\n\n## Spec References\n\n- [User story + BDD scenario reference]\n- [Product documentation links]\n- [Any other relevant specifications]\n\n## Test Sequence\n\n<!-- Order tests from simplest to most complex -->\n<!-- Each test should build on previous ones -->\n<!-- Test names should describe business behavior, not implementation -->\n\n1. [Simplest case - usually happy path with minimal setup]\n2. [Next layer of complexity - often validation or business rules]\n3. [Edge cases or alternative paths]\n4. [Error scenarios]\n5. [Complex interactions if applicable]\n<!-- Continue as needed -->\n\n## Test Strategy\n\n- **Test Type**: Unit tests with mocked dependencies\n- **Isolation**: Mock all external dependencies (database, APIs, file system)\n- **Speed**: Tests should run in milliseconds\n- **Coverage**: Each business rule needs at least one test\n\n## Boundaries & Integration Points\n\n- **External Systems**: [What to mock in unit tests]\n- **Internal Patterns**: [Existing domain patterns to follow]\n- **Integration Points**: [Where integration tests may be needed]\n\n## Dependencies\n\n- **Depends on**: [Other features or components that must exist]\n- **Blocks/Enables**: [What can't proceed until this is done / What this unlocks]\n\n## Notes\n\n[Important clarifications, assumptions, or open questions]\n```\n\n## Examples\n\nHere are examples of how the generated roadmaps should look, when properly following the roadmap template format above.\n\n### Example 1: Todo Archive Feature\n\n```markdown\n# Domain/Business Logic Roadmap: Archive Completed Todos\n\n## Overview\n\nAllows users to archive completed todos to keep their active list clean. Archived todos move to a separate list and can be restored if needed.\n\n## System View\n\n\\`\\`\\`mermaid\ngraph LR\nAPI[REST API] --> Service[TodoService]\nService --> Repo[Repository]\nService --> Events[Event Bus]\nRepo --> DB[(Database)]\n\\`\\`\\`\n\n## Spec References\n\n- STORY-123: User archives completed todos\n\n## Test Sequence\n\n1. Archive a completed todo successfully\n2. Prevent archiving of incomplete todos\n3. Verify archived todo is removed from active list\n4. Verify archived todo appears in archived list\n5. Restore an archived todo to active list\n6. Handle archiving non-existent todo\n7. Prevent duplicate archiving of same todo\n\n## Test Strategy\n\n- **Test Type**: Unit tests with mocked dependencies\n- **Isolation**: Mock TodoRepository for persistence\n- **Speed**: Tests should run in milliseconds\n- **Coverage**: Each business rule needs at least one test\n\n## Boundaries & Integration Points\n\n- **External Systems**: Database (mock in unit tests)\n- **Internal Patterns**: Service/Repository pattern from existing code\n- **Integration Points**: Acceptance tests will verify full REST to database flow\n\n## Dependencies\n\n- **Depends on**: Todo completion feature\n- **Blocks/Enables**: Archive analytics dashboard, Bulk archive operations\n\n## Notes\n\n- Consider soft delete pattern for data recovery\n- Archive timestamp will be added in future iteration\n```\n\n### Example 2: User Registration Feature\n\n```markdown\n# Domain/Business Logic Roadmap: User Registration\n\n## Overview\n\nEnables new users to create accounts with email and password. Includes validation, uniqueness checks, and welcome email triggering.\n\n## System View\n\n\\`\\`\\`mermaid\ngraph TD\nInput[Registration Data] --> Service[UserService]\nService --> Validator[ValidationRules]\nService --> Repo[UserRepository]\nService --> Email[EmailService]\nService --> Prefs[PreferencesService]\nRepo --> DB[(Database)]\nEmail --> Queue[Message Queue]\n\\`\\`\\`\n\n## Spec References\n\n- STORY-456: New user registration\n- Security requirements document section 3.2\n- Email service API documentation\n\n## Test Sequence\n\n1. Registers user with valid email and password\n2. Validates email format\n3. Enforces minimum password length\n4. Enforces password complexity requirements\n5. Prevents registration with existing email\n6. Treats email addresses as case-insensitive when checking uniqueness\n7. Passwords must never be stored in plaintext, only as secrets\n8. Triggers welcome email on successful registration\n9. Sets default user preferences\n10. Handles registration when email service unavailable\n\n## Test Strategy\n\n- **Test Type**: Unit tests with mocked dependencies\n- **Isolation**: Mock UserRepository, EmailService, PreferencesService\n- **Speed**: Tests should run in milliseconds\n- **Coverage**: Each validation rule and business flow needs coverage\n\n## Boundaries & Integration Points\n\n- **External Systems**: Database, Email service (mock in unit tests)\n- **Internal Patterns**: Domain events pattern for email triggering\n- **Integration Points**: Acceptance tests will verify full registration flow including real email\n\n## Dependencies\n\n- **Depends on**: Email service configuration, Password policy definition\n- **Blocks/Enables**: User login, Profile customization, Password reset\n\n## Notes\n\n- Consider rate limiting for registration attempts\n- GDPR compliance for data storage confirmed with legal\n- Two-factor authentication planned for Q3\n```\n","# AI Technical Implementation Roadmap Template\n\nCreate a high-level roadmap for a single technical implementation element (adapter, infrastructure piece) that complements the behavioral implementation. This roadmap guides test sequence without prescribing implementation details: those should emerge through the TDD process.\n\nWhen done, ask user if the roadmap file should be saved to /ai-roadmaps/technical directory. Create directory if not exists.\n\n**First, if anything is unclear about the technical requirements or constraints, ask for clarification rather than making assumptions.**\n\n## Core Testing Principle for Technical Implementation\n\nWhen generating test sequences, remember:\n\n- Test this element's responsibilities, not domain behavior\n- The domain already has comprehensive unit tests: trust them\n- Focus on what THIS element does: parsing, formatting, error translation, etc.\n- Don't re-test business rules through the adapter\n\n## Format\n\n```markdown\n# Technical Implementation Roadmap: [Specific Element Name]\n\n## Overview\n\n[2-3 sentences describing the technical element's purpose and how it supports the business feature]\n\n## Element Type\n\n[Input Adapter | Output Adapter | Infrastructure | Cache | Queue | Other]\n\n## System View\n\n[Create a diagram ONLY if the element has complex integration points,\ndata transformations, or multi-step flows that benefit from visualization.\nOtherwise, write \"No diagram needed - [brief reason]\"]\n\n<!-- If diagram is beneficial, choose appropriate type:\n- Mermaid diagram for data flow through the adapter\n- Sequence diagram for multi-step API interactions\n- State diagram for connection management\n- Or describe the integration in text -->\n<!-- For simple flows like \"HTTP request → validation → domain → response\", text is sufficient -->\n\n## Integration Points\n\n- **Connects to Domain**: [How it interfaces with business logic]\n- **External Dependencies**: [What external systems it interacts with]\n- **Data Flow**: [Brief description of input → processing → output]\n<!-- Include a mermaid diagram only if the flow is complex enough to justify it -->\n\n## Spec References\n\n- [Technical task ticket reference (e.g., TECH-101)]\n- [Technical standards or architecture decision records]\n- [API documentation or interface specifications]\n\n## Test Sequence\n\n<!-- TEST NAMING: Test names should always describe behavior, not implementation details -->\n<!-- \"Behavior\" for technical elements = the technical promise (what it does for its users) -->\n<!-- Users here = other developers, systems, or internal modules -->\n<!-- Test names should describe WHAT happens, not HOW -->\n\n<!-- GOOD test names (behavior-focused): -->\n<!-- ✅ \"parses valid input format\" -->\n<!-- ✅ \"returns 404 for non-existent resources\" -->\n<!-- ✅ \"formats output according to specification\" -->\n<!-- ✅ \"persists data with generated ID\" -->\n\n<!-- BAD test names (implementation details): -->\n<!-- ❌ \"uses regex to parse input\" -->\n<!-- ❌ \"calls repository.save method\" -->\n<!-- ❌ \"checks error.type === 'NOT_FOUND'\" -->\n<!-- ❌ \"executes INSERT statement\" -->\n\n<!-- WHAT TO TEST by element type (not domain rules): -->\n<!-- Input Adapters: parsing, validation, error code translation -->\n<!-- Output Adapters: formatting, serialization, connection handling -->\n<!-- Infrastructure: persistence operations, caching behavior, queue management -->\n\n1. [Simplest case - usually happy path with minimal setup]\n2. [Error handling specific to this element]\n3. [Edge cases for this element's responsibilities]\n4. [Integration scenarios if applicable]\n<!-- Continue as needed, focused on this single element -->\n\n<!-- ANTI-PATTERNS to avoid: -->\n<!-- ❌ Re-testing domain rules through the adapter -->\n<!-- ✅ Test only technical translation (e.g., \"returns 400 for validation errors\") -->\n<!-- ❌ Testing through multiple layers -->\n<!-- ✅ Test only this element's direct responsibilities -->\n\n## Test Strategy\n\n<!-- IMPORTANT: Technical elements generally don't use unit tests; that's for domain logic -->\n\n**Primary approach**: [Choose ONE based on your main dependency]\n\n- **Integration Tests** — For elements with managed dependencies (your DB, cache, stdin/stdout)\n  - Use REAL domain logic + REAL managed dependencies\n  - Always MOCK unmanaged dependencies (external APIs)\n- **Contract Tests** — For elements primarily calling unmanaged dependencies (Stripe, SendGrid)\n  - Use REAL domain logic (never mock the business logic)\n  - Toggleable: MOCK for fast dev/CI, REAL for pre-deploy validation\n\n## Technical Constraints\n\n<!-- Include relevant NFR categories; add others if needed -->\n\n- **Performance**: [Specific requirements or \"Standard performance expectations\"]\n- **Compatibility**: [Versions, protocols, standards or \"No special compatibility requirements\"]\n- **Security**: [Authentication, encryption, access control or \"Standard security practices\"]\n\n## Dependencies\n\n- **Depends on**: [What must exist before this can be built]\n- **Blocks/Enables**: [What can't proceed until this is done / What this unlocks]\n\n## Notes\n\n[Important constraints, clarifications, or open questions]\n```\n\n## Examples\n\nHere are examples of how the generated roadmaps should look, when properly following the roadmap template format above.\n\n### Example 1: REST Endpoint (Input Adapter)\n\n```markdown\n# Technical Implementation Roadmap: Archive Todo REST Endpoint\n\n## Overview\n\nREST endpoint that receives archive requests from the frontend and delegates to the todo domain service. Provides standard HTTP interface for the archive todo feature.\n\n## Element Type\n\nInput Adapter\n\n## System View\n\nNo diagram needed - simple request/response flow with single domain service dependency\n\n## Integration Points\n\n- **Connects to Domain**: Calls TodoService.archiveTodo(id)\n- **External Dependencies**: None (receives HTTP requests)\n- **Data Flow**: HTTP request → validation → domain call → HTTP response\n\n## Spec References\n\n- TECH-101: Archive todo REST endpoint task\n- API design guidelines document\n- OpenAPI schema definition v2\n\n## Test Sequence\n\n1. Archives todo successfully and returns 200 with archived todo\n2. Returns 404 when todo doesn't exist\n3. Returns 400 when todo is already archived\n4. Returns 401 for unauthenticated requests\n5. Returns 422 for invalid request format\n6. Returns appropriate error for malformed JSON\n7. Returns 429 when rate limit exceeded\n\n## Test Strategy\n\n**Primary approach**: Integration Tests\n\n- Test with real Express/NestJS app instance\n- Use real TodoService and real test database\n- Mock only external unmanaged services if any\n\n## Technical Constraints\n\n- **Performance**: Response within 200ms (p95)\n- **Compatibility**: REST API v2 standards, OpenAPI 3.0\n- **Security**: JWT authentication required, rate limit 100/min per user\n\n## Dependencies\n\n- **Depends on**: TodoService domain implementation, Auth middleware\n- **Blocks/Enables**: Frontend archive button implementation\n\n## Notes\n\n- Follow existing REST conventions from other endpoints\n- Include OpenAPI documentation annotations\n- Consider adding request ID for tracing\n```\n\n### Example 2: Email Notification Sender (Output Adapter)\n\n```markdown\n# Technical Implementation Roadmap: Archive Confirmation Email Sender\n\n## Overview\n\nOutput adapter that sends email notifications when todos are archived. Integrates with SendGrid API to deliver transactional emails with proper formatting and tracking.\n\n## Element Type\n\nOutput Adapter\n\n## System View\n\n\\`\\`\\`mermaid\nsequenceDiagram\nDomain->>EmailSender: TodoArchived event\nEmailSender->>EmailSender: Render template\nEmailSender->>SendGrid: API call\nSendGrid-->>EmailSender: Response/Error\nEmailSender->>Logger: Log result\n\\`\\`\\`\n\n## Integration Points\n\n- **Connects to Domain**: Listens to TodoArchived domain events\n- **External Dependencies**: SendGrid API\n- **Data Flow**: Domain event → template rendering → SendGrid API call → delivery status\n\n## Spec References\n\n- TECH-107: Email notification implementation\n- Email design system documentation\n- SendGrid integration guide\n\n## Test Sequence\n\n1. Sends email with correct recipient and subject\n2. Populates template with todo details\n3. Handles SendGrid API errors gracefully\n4. Retries on temporary failures (rate limits, network issues)\n5. Logs permanent failures without throwing\n6. Respects email preferences (opt-out flag)\n7. Includes proper tracking parameters\n8. Handles missing or invalid email addresses\n\n## Test Strategy\n\n**Primary approach**: Contract Tests\n\n- Use real domain events and template engine\n- Toggle SendGrid: MOCK for dev/CI, REAL for staging validation\n- Verify our assumptions about SendGrid's API behavior\n\n## Technical Constraints\n\n- **Performance**: Non-blocking, async processing\n- **Compatibility**: SendGrid API v3\n- **Security**: API keys in environment variables, PII handling compliance\n\n## Dependencies\n\n- **Depends on**: Domain event system, Email template engine\n- **Blocks/Enables**: Email analytics dashboard\n\n## Notes\n\n- Consider batching for high-volume scenarios\n- Template changes need design team approval\n- Monitor SendGrid quota usage\n```\n\n---\n\n⬅️ Back to: [Appendix D](../../appendices/appendix-d-handling-technical-implementation-details.md)\n","# Project Context\n\n## General\n\n{{GENERAL_CONTEXT}}\n\nSummarize what you learned and confirm when ready.\n","import greenAndStopSrc from \"./green-&-stop.md\";\nimport redAndStopSrc from \"./red-&-stop.md\";\nimport refactorAndStopSrc from \"./refactor-&-stop.md\";\n\nexport const greenAndStop: string = greenAndStopSrc;\nexport const redAndStop: string = redAndStopSrc;\nexport const refactorAndStop: string = refactorAndStopSrc;\n","Enter GREEN phase as defined in the AAID rules file:\n\n<!-- Rules file should have been automatically injected by IDE/CLI -->\n\n-   Enforce GREEN phase rules and execute phase instructions\n-   STOP and AWAIT USER REVIEW\n-   If rules file missing, STOP and request it\n","Enter RED phase as defined in the AAID rules file:\n\n<!-- Rules file should have been automatically injected by IDE/CLI -->\n\n-   Enforce RED phase rules and execute phase instructions\n-   STOP and AWAIT USER REVIEW\n-   If rules file missing, STOP and request it\n","Enter REFACTOR phase as defined in the AAID rules file.\n\n<!-- Rules file should have been automatically injected by IDE/CLI -->\n\n-   Enforce REFACTOR phase rules and execute phase instructions\n-   STOP and AWAIT USER REVIEW\n-   If rules file missing, STOP and request it\n"]}